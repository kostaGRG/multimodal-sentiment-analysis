{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Multimodal sentiment analysis (text/image) in MVSA dataset"
      ],
      "metadata": {
        "id": "V5WcleALgJC4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Reading data from original MVSA-single dataset"
      ],
      "metadata": {
        "id": "bTBVj2iwgrQX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import libraries, get access to texts,images and labels of the dataset\n"
      ],
      "metadata": {
        "id": "IQBJ9GfqLNEN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import necessary libraries that will be used in this notebook"
      ],
      "metadata": {
        "id": "aOBAeX95EeXt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from zipfile import ZipFile\n",
        "import cv2\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "import h5py\n",
        "\n",
        "# MVSA_SINGLE: BOOLEAN VARIABLE. IF TRUE, MVSA-SINGLE DATASET WILL BE PROCESSED, OTHERWISE MVSA-MULTIPLE\n",
        "MVSA_SINGLE = True"
      ],
      "metadata": {
        "id": "5rO0OnrO4W5b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "unzip the zipped files"
      ],
      "metadata": {
        "id": "AhTABQh6aL_m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if MVSA_SINGLE:\n",
        "  zf = ZipFile('/content/drive/MyDrive/sentiment-analysis/notebooks/MVSA-Single.zip', 'r')\n",
        "  zf.extractall('./data')\n",
        "  zf.close()\n",
        "else:\n",
        "  zf = ZipFile('/content/drive/MyDrive/sentiment-analysis/notebooks/MVSA-Multiple.zip', 'r')\n",
        "  zf.extractall('./data')\n",
        "  zf.close()"
      ],
      "metadata": {
        "id": "QBSmECcj4TtH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Get data and label paths"
      ],
      "metadata": {
        "id": "mJav6ImNaPri"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if MVSA_SINGLE:\n",
        "  mvsa_single_data_path = './data/MVSA_Single/data'\n",
        "  mvsa_single_label_path = './data/MVSA_Single/labelResultAll.txt'\n",
        "else:\n",
        "  mvsa_multiple_data_path = './data/MVSA/data'\n",
        "  mvsa_multiple_label_path = './data/MVSA/labelResultAll.txt'\n",
        "\n",
        "IMAGE_SIZE = (224, 224)\n",
        "NUM_CHANNELS = 3"
      ],
      "metadata": {
        "id": "FVmzNvQSjCtI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create functions"
      ],
      "metadata": {
        "id": "_80J9dgfalPl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Read a single text file\n",
        "def read_text_file(path):\n",
        "    return open(path, 'r', encoding='latin-1').read()\n",
        "\n",
        "# Read a single image file and resize it to the desired size.\n",
        "# If the image is corrupted, store this info to invalid_ID parameter.\n",
        "def read_image_file(path):\n",
        "    try:\n",
        "        image = cv2.imread(path)[:, :, ::-1] #, cv2.COLOR_BGR2RGB)\n",
        "        image = cv2.resize(image, IMAGE_SIZE, interpolation = cv2.INTER_AREA)\n",
        "\n",
        "        invalid_ID = -1\n",
        "    except:\n",
        "        image = np.zeros((IMAGE_SIZE[0], IMAGE_SIZE[1], NUM_CHANNELS))\n",
        "        invalid_ID = int(os.path.split(path)[1].split('.')[0])\n",
        "    return image, invalid_ID\n",
        "\n",
        "# Read file of labels\n",
        "def read_labels_file(path):\n",
        "    dataframe = pd.read_csv(path, sep=\"\\s+|,\", engine=\"python\")\n",
        "    return dataframe\n",
        "\n",
        "\n",
        "def get_data_paths(path, extension):\n",
        "    ''' Get list of data paths with input extension and sort by its filename (ID)\n",
        "    path: Folder path\n",
        "    extension: File extension wants to get\n",
        "    '''\n",
        "    paths = os.listdir(path)\n",
        "    paths = list(filter(lambda x: x.endswith(extension), paths))\n",
        "    paths.sort(key = lambda x : int(x.split('.')[0]))\n",
        "    paths = [os.path.join(path, x) for x in paths]\n",
        "    return paths\n",
        "\n",
        "# Get the image with its unique ID in the dataset, given the path as argument.\n",
        "def get_image_with_id(path):\n",
        "    filename = os.path.split(path)[1]\n",
        "    ID = int(filename.split('.')[0])\n",
        "    image = read_image_file(path)\n",
        "    return (ID, image)\n",
        "\n",
        "# Decide about the multimodal label, based on the text and the image label. The final label is decided through the rules:\n",
        "# 1. if both text and image labels have the same value -> multimodal label will have the same value also\n",
        "# 2. if text label equals to negative and image label equals to positive or vice versa -> multimodal label can't be predicted and it's considered as 'unknown'\n",
        "# 3. if one label is neutral and the other one is positive or negative -> multimodal label will be equal to the non neutral label\n",
        "def multimodal_label(text_label, image_label):\n",
        "    if text_label == image_label:\n",
        "        label = text_label\n",
        "    elif (text_label == 'positive' and image_label == 'negative') or (text_label == 'negative' and image_label == 'positive'):\n",
        "        label = 'invalid'\n",
        "    elif (text_label == 'neutral' and image_label != 'neutral') or (text_label != 'neutral' or image_label == 'neutral'):\n",
        "        label = image_label if text_label == 'neutral' else text_label\n",
        "    return label\n",
        "\n",
        "# Collect all the texts stored in the dataset\n",
        "def create_text_data(path):\n",
        "    texts = []\n",
        "    text_paths = get_data_paths(path, '.txt')\n",
        "\n",
        "    print('Reading text data')\n",
        "    for text_path in tqdm(text_paths):\n",
        "        text = read_text_file(text_path).rstrip('\\n')\n",
        "        texts.append(text)\n",
        "\n",
        "    return texts\n",
        "\n",
        "# Collect all the images stored in the dataset and check for each image if it's corrupted.\n",
        "# If the image is corrupted, then its ID is stored in a separate array with all the invalid IDs.\n",
        "def create_image_data(path):\n",
        "    images = []\n",
        "    invalid_indices = []\n",
        "    image_paths = get_data_paths(path, '.jpg')\n",
        "\n",
        "    print('Reading image data')\n",
        "    for image_path in tqdm(image_paths):\n",
        "        image, invalid_ID = read_image_file(image_path)\n",
        "        images.append(image)\n",
        "\n",
        "        if invalid_ID != -1:\n",
        "            invalid_indices.append(invalid_ID)\n",
        "\n",
        "    images = np.array(images, dtype='uint8')\n",
        "    return images, invalid_indices"
      ],
      "metadata": {
        "id": "9Kin_BG1jaJh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# there are 3 annotators labelling each modality labels in the MVSA-Multiple dataset\n",
        "# merge those 3 label pairs into 1 pair by taking majority vote on each modality label\n",
        "# since there are only 3 different labels, if 1 modality receives 3 different labels from 3 annotators\n",
        "# => the data pair is considered invalid\n",
        "def merge_multi_label(dataframe):\n",
        "    anno_1 = list(dataframe.loc[:, ['text', 'image']].itertuples(index=False, name=None))\n",
        "    anno_2 = list(dataframe.loc[:, ['text.1', 'image.1']].itertuples(index=False, name=None))\n",
        "    anno_3 = list(dataframe.loc[:, ['text.2', 'image.2']].itertuples(index=False, name=None))\n",
        "    IDs = list(dataframe.iloc[:, 0])\n",
        "\n",
        "    valid_pairs = []\n",
        "\n",
        "    for i in range(len(anno_1)):\n",
        "        pairs = [anno_1[i], anno_2[i], anno_3[i]]\n",
        "        ID = IDs[i]\n",
        "\n",
        "        text_labels = [pair[0] for pair in pairs]\n",
        "        image_labels = [pair[1] for pair in pairs]\n",
        "\n",
        "        max_occur_text_label = max(text_labels, key=text_labels.count)\n",
        "        max_occur_image_label = max(image_labels, key=image_labels.count)\n",
        "\n",
        "        if text_labels.count(max_occur_text_label) > 1 and image_labels.count(max_occur_image_label) > 1:\n",
        "          valid_pair = (ID, max_occur_text_label, max_occur_image_label)\n",
        "        else:\n",
        "          valid_pair = (ID, 'invalid', 'invalid')\n",
        "\n",
        "        valid_pairs.append(valid_pair)\n",
        "    valid_dataframe = pd.DataFrame(valid_pairs, columns=['ID', 'text', 'image'])\n",
        "    return valid_dataframe\n",
        "\n",
        "# Create the multimodal labels, using the previous assistant functions.\n",
        "# Based on the value of argument \"multiple\" choose between the MVSA-Single and the MVSA-Multiple processing.\n",
        "def create_multimodal_labels(path, multiple=False, mappings=False):\n",
        "    dataframe = read_labels_file(path)\n",
        "    labels = []\n",
        "\n",
        "    if multiple == True:\n",
        "      dataframe = merge_multi_label(dataframe)\n",
        "\n",
        "    for label_pair in dataframe.loc[:, ['text', 'image']].values:\n",
        "        label = multimodal_label(label_pair[0], label_pair[1])\n",
        "        labels.append(label)\n",
        "\n",
        "    if mappings == True:\n",
        "        label_map = {}\n",
        "        for i in range(len(labels)):\n",
        "            ID = dataframe.iloc[i, 0]\n",
        "            label_map[ID] = labels[i]\n",
        "        return label_map\n",
        "\n",
        "    return np.array(labels, dtype='object')\n",
        "\n",
        "# Read the original labels from the initial file of the .zip and map them with the correct pair of text and image.\n",
        "def create_original_labels(path, multiple=False):\n",
        "    dataframe = read_labels_file(path)\n",
        "    if multiple == True:\n",
        "      dataframe = merge_multi_label(dataframe)\n",
        "    text_labels = dataframe['text'].to_numpy()\n",
        "    image_labels = dataframe['image'].to_numpy()\n",
        "    return text_labels, image_labels\n",
        "\n",
        "# Remove pairs that have invalid indices\n",
        "def remove_invalid(data, indices):\n",
        "    valid_data = []\n",
        "    for i in range(len(data)):\n",
        "        if i not in indices:\n",
        "            valid_data.append(data[i])\n",
        "    return valid_data"
      ],
      "metadata": {
        "id": "84-II1YeqAGP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Cleaning dataset for multimodal analysis"
      ],
      "metadata": {
        "id": "oYZwI-tZ2Wi9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if MVSA_SINGLE:\n",
        "  # Get texts, images, labels and create multimodal labels\n",
        "  mvsa_single_texts = create_text_data(mvsa_single_data_path)\n",
        "  mvsa_single_images, mvsa_single_images_invalid_indices = create_image_data(mvsa_single_data_path)\n",
        "  mvsa_single_multimodal_labels = create_multimodal_labels(mvsa_single_label_path)\n",
        "  mvsa_single_text_labels, mvsa_single_image_labels = create_original_labels(mvsa_single_label_path)\n",
        "  num_mvsa_single = len(mvsa_single_texts)\n",
        "\n",
        "  # Exclude pairs with invalid indices, either because of a corrupted image or unknown multimodal label\n",
        "  mvsa_single_multimodal_labels_invalid_indices = [i for i in range(num_mvsa_single) if mvsa_single_multimodal_labels[i] == 'invalid']\n",
        "  print('Number of text-image pair in MVSA-Single:', num_mvsa_single)\n",
        "  mvsa_single_invalid_indices = []\n",
        "  mvsa_single_invalid_indices.extend(mvsa_single_images_invalid_indices) # corrupted images\n",
        "  mvsa_single_invalid_indices.extend(mvsa_single_multimodal_labels_invalid_indices)\n",
        "  mvsa_single_invalid_indices = list(set(mvsa_single_invalid_indices))\n",
        "  print('Number of invalid data in MVSA-Single:', len(mvsa_single_invalid_indices))\n",
        "  mvsa_single_texts_valid = remove_invalid(mvsa_single_texts, mvsa_single_invalid_indices)\n",
        "  mvsa_single_images_valid = remove_invalid(mvsa_single_images, mvsa_single_invalid_indices)\n",
        "  mvsa_single_multimodal_labels_valid = remove_invalid(mvsa_single_multimodal_labels, mvsa_single_invalid_indices)\n",
        "  mvsa_single_text_labels_valid = remove_invalid(mvsa_single_text_labels, mvsa_single_invalid_indices)\n",
        "  mvsa_single_image_labels_valid = remove_invalid(mvsa_single_image_labels, mvsa_single_invalid_indices)\n",
        "  num_mvsa_single_valid = len(mvsa_single_texts_valid)\n",
        "  print('Number of text-image pair in MVSA-Single after removing invalid data:', num_mvsa_single_valid)\n",
        "\n",
        "  # save the cleaned dataset\n",
        "  with h5py.File('mvsa-single-{}.hdf5'.format(num_mvsa_single_valid), 'w') as f:\n",
        "      f.create_dataset('texts', data = mvsa_single_texts_valid)\n",
        "      f.create_dataset('images', data = mvsa_single_images_valid)\n",
        "      f.create_dataset('multimodal-labels', data = mvsa_single_multimodal_labels_valid)\n",
        "      f.create_dataset('text-labels', data = mvsa_single_text_labels_valid)\n",
        "      f.create_dataset('image-labels', data = mvsa_single_image_labels_valid)\n",
        "\n",
        "  from google.colab import files\n",
        "  files.download('./sample_data/mvsa-single-4511.hdf5')\n",
        "\n",
        "else:\n",
        "  # Get texts, images, labels and create multimodal labels\n",
        "  mvsa_multiple_texts = create_text_data(mvsa_multiple_data_path)\n",
        "  mvsa_multiple_images, mvsa_multiple_images_invalid_indices = create_image_data(mvsa_multiple_data_path)\n",
        "  mvsa_multiple_multimodal_labels = create_multimodal_labels(mvsa_multiple_label_path, multiple=True)\n",
        "  mvsa_multiple_text_labels, mvsa_multiple_image_labels = create_original_labels(mvsa_multiple_label_path, multiple=True)\n",
        "  num_mvsa_multiple = len(mvsa_multiple_texts)\n",
        "\n",
        "  # Exclude pairs with invalid indices, either because of a corrupted image or unknown multimodal label\n",
        "  mvsa_multiple_multimodal_labels_invalid_indices = [i for i in range(num_mvsa_multiple) if mvsa_multiple_multimodal_labels[i] == 'invalid']\n",
        "  print('Number of text-image pair in MVSA-Multiple:', num_mvsa_multiple)\n",
        "  mvsa_multiple_invalid_indices = []\n",
        "  mvsa_multiple_invalid_indices.extend(mvsa_multiple_images_invalid_indices)\n",
        "  print('Number of invalid data in images: ',len(mvsa_multiple_invalid_indices))\n",
        "  mvsa_multiple_invalid_indices.extend(mvsa_multiple_multimodal_labels_invalid_indices)\n",
        "  mvsa_multiple_invalid_indices = list(set(mvsa_multiple_invalid_indices))\n",
        "  print('Number of invalid data in MVSA-Multiple:', len(mvsa_multiple_invalid_indices))\n",
        "  mvsa_multiple_texts_valid = remove_invalid(mvsa_multiple_texts, mvsa_multiple_invalid_indices)\n",
        "  mvsa_multiple_images_valid = remove_invalid(mvsa_multiple_images, mvsa_multiple_invalid_indices)\n",
        "  mvsa_multiple_multimodal_labels_valid = remove_invalid(mvsa_multiple_multimodal_labels, mvsa_multiple_invalid_indices)\n",
        "  mvsa_multiple_text_labels_valid = remove_invalid(mvsa_multiple_text_labels, mvsa_multiple_invalid_indices)\n",
        "  mvsa_multiple_image_labels_valid = remove_invalid(mvsa_multiple_image_labels, mvsa_multiple_invalid_indices)\n",
        "  num_mvsa_multiple_valid = len(mvsa_multiple_texts_valid)\n",
        "  print('Number of text-image pair in MVSA-Multiple after removing invalid data:', num_mvsa_multiple_valid)\n",
        "\n",
        "  # save the cleaned dataset\n",
        "  with h5py.File('mvsa-multiple-{}.hdf5'.format(num_mvsa_multiple_valid), 'w') as f:\n",
        "      f.create_dataset('texts', data = mvsa_multiple_texts_valid)\n",
        "      f.create_dataset('images', data = mvsa_multiple_images_valid)\n",
        "      f.create_dataset('multimodal-labels', data = mvsa_multiple_multimodal_labels_valid)\n",
        "      f.create_dataset('text-labels', data = mvsa_multiple_text_labels_valid)\n",
        "      f.create_dataset('image-labels', data = mvsa_multiple_image_labels_valid)\n",
        "\n",
        "  from google.colab import files\n",
        "  files.download('./mvsa-multiple-17024.hdf5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QJwOGdsPpern",
        "outputId": "68439338-9f6e-4bb4-9dd2-a8eee4c02f8b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading text data\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4869/4869 [00:00<00:00, 37579.80it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading image data\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4869/4869 [00:59<00:00, 81.53it/s] \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Cleaning dataset for text only analysis"
      ],
      "metadata": {
        "id": "fSrZuB6Y4aBG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if MVSA_SINGLE:\n",
        "  # Get texts and text labels\n",
        "  mvsa_single_texts = create_text_data(mvsa_single_data_path)\n",
        "  # mvsa_single_multimodal_labels = create_multimodal_labels(mvsa_single_label_path)\n",
        "  mvsa_single_text_labels = create_original_labels(mvsa_single_label_path)[0]\n",
        "  num_mvsa_single = len(mvsa_single_texts)\n",
        "\n",
        "  # Store the cleaned dataset consisting only of texts\n",
        "  with h5py.File('mvsa-single-{}.hdf5'.format(num_mvsa_single), 'w') as f:\n",
        "    f.create_dataset('texts', data = mvsa_single_texts)\n",
        "    f.create_dataset('text-labels', data = mvsa_single_text_labels)\n",
        "else:\n",
        "  # Get texts and text labels\n",
        "  mvsa_multiple_texts = create_text_data(mvsa_multiple_data_path)\n",
        "  mvsa_multiple_text_labels = create_original_labels(mvsa_multiple_label_path,multiple=True)[0]\n",
        "  print(mvsa_multiple_text_labels)\n",
        "  num_mvsa_multiple = len(mvsa_multiple_texts)\n",
        "\n",
        "  # Store the cleaned dataset consisting only of texts\n",
        "  with h5py.File('mvsa-multiple-{}.hdf5'.format(num_mvsa_multiple), 'w') as f:\n",
        "    f.create_dataset('texts', data = mvsa_multiple_texts)\n",
        "    f.create_dataset('text-labels', data = mvsa_multiple_text_labels)"
      ],
      "metadata": {
        "id": "c3_I0-K84eR_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Cleaning dataset for image only analysis"
      ],
      "metadata": {
        "id": "dMMDy8XY6Ehu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if MVSA_SINGLE:\n",
        "  # Get images and image labels\n",
        "  mvsa_single_images, invalid_indices = create_image_data(mvsa_single_data_path)\n",
        "  temp,mvsa_single_image_labels = create_original_labels(mvsa_single_label_path)\n",
        "  num_mvsa_single = len(mvsa_single_images)\n",
        "  print(len(invalid_indices))\n",
        "\n",
        "  # Store the cleaned dataset consisting only of images\n",
        "  with h5py.File('mvsa-single-{}.hdf5'.format(num_mvsa_single), 'w') as f:\n",
        "    f.create_dataset('images', data = mvsa_single_images)\n",
        "    f.create_dataset('image-labels', data = mvsa_single_image_labels)\n",
        "else:\n",
        "  # Get images and image labels\n",
        "  mvsa_multiple_images, invalid_indices = create_image_data(mvsa_multiple_data_path)\n",
        "  temp,mvsa_multiple_image_labels = create_original_labels(mvsa_multiple_label_path,multiple=True)\n",
        "  num_mvsa_multiple = len(mvsa_multiple_images)\n",
        "  print(len(invalid_indices))\n",
        "\n",
        "  # Remove corrupted images\n",
        "  mvsa_multiple_image_labels_invalid_indices = [i for i in range(num_mvsa_multiple) if mvsa_multiple_image_labels[i] == 'invalid']\n",
        "  print('Number of text-image pair in MVSA-Multiple:', num_mvsa_multiple)\n",
        "  mvsa_multiple_invalid_indices = []\n",
        "  # mvsa_multiple_invalid_indices.extend(mvsa_multiple_texts_duplicated_indices)\n",
        "  mvsa_multiple_invalid_indices.extend(invalid_indices)\n",
        "  mvsa_multiple_invalid_indices.extend(mvsa_multiple_image_labels_invalid_indices)\n",
        "  print('Number of invalid data in images: ',len(mvsa_multiple_invalid_indices))\n",
        "  mvsa_multiple_invalid_indices = list(set(mvsa_multiple_invalid_indices))\n",
        "  mvsa_multiple_images_valid = remove_invalid(mvsa_multiple_images, mvsa_multiple_invalid_indices)\n",
        "  mvsa_multiple_image_labels_valid = remove_invalid(mvsa_multiple_image_labels, mvsa_multiple_invalid_indices)\n",
        "  num_mvsa_multiple_valid = len(mvsa_multiple_images_valid)\n",
        "  print('Number of text-image pair in MVSA-Multiple after removing invalid data:', num_mvsa_multiple_valid)\n",
        "  print(np.unique(mvsa_multiple_image_labels_valid))\n",
        "\n",
        "  # Store the cleaned dataset consisting only of images\n",
        "  with h5py.File('mvsa-multiple-{}_image.hdf5'.format(num_mvsa_multiple_valid), 'w') as f:\n",
        "    f.create_dataset('images', data = mvsa_multiple_images_valid)\n",
        "    f.create_dataset('image-labels', data = mvsa_multiple_image_labels_valid)"
      ],
      "metadata": {
        "id": "jo0OGr2_6jsv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}